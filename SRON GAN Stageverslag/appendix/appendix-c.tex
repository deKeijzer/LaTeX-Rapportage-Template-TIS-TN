\chapter{Evaluatie stage opdracht}
De reden van deze Appendix is om de complexiteit en de ondervonden moeilijkheden te benadrukken.
De complexiteit van de stage opdracht is ten zeerste onderschat. Het idee dat twee neurale netwerken, ik noem ze modellen, tegen elkaar een spel aan het spelen zijn om vervolgens steeds beter te worden klinkt simpel. Er zijn voldoende artikelen over het maken van een GAN. Echter verbloemen deze allen de realiteit. Er worden modellen gepresenteerd die zichzelf al bewezen hebben op perfecte benchmark datasets zoals CelebFaces \cite{liu2018large}. Vergelijk dit met het overtrekken van een tekening, in plaats van volledig zelfstandig een abstract kunstwerk maken. 
Helaas komt de complexiteit en de moeilijkheden bij het ontwerpen van een GAN voor een fysisch probleem in vrijwel geen enkel wetenschappelijk artikel naar voren. Zoals de oud directeur van SRON tijdens een vergadering zei ‘It almost seems like black magic’. In zekere zin zou het ook zo genoemd kunnen worden. Het instrument heeft (te) veel knoppen om aan te draaien, waarbij een zeer kleine verandering aan een enkele knop een chaotische uitkomst op het resultaat kan hebben.
Mocht ik echt iets wijzer willen worden over GANs, dan was de enige optie om wetenschappelijke artikelen te lezen. Het kostte ongeveer 10-15 artikelen om een beetje een algemeen beeld te krijgen van de meest simpele GAN. Een kleine maand later was het duidelijk wat er geprogrammeerd moest worden. Ondertussen was het ook duidelijk dat GANs op het uiteinde zitten van de huidige ontwikkelingen binnen het vakgebied van machine learning. Het is een actief onderzoeksgebied, voor veel problemen die ik tegen kwam is simpelweg nog geen algemene oplossing te vinden. Daarbij, iedere keer dat ik een goed resultaat leek te hebben bleek dit toch niet het geval. M.a.w. , heb je een goed resultaat? Dan is het vrijwel zo dat er iets niet klopt. Dit blijkt uit een artikel van de director of AI bij Tesla \cite{a_recipe_for_training_neural_networks}. Dit artikel staat haaks op het grootste deel van de (commerciële) artikelen m.b.t. AI, maar de inhoud representeert naar mijn ervaring gedurende dit studiejaar de realiteit. 
Dat het moeilijk is om een GAN te laten convergeren is inmiddels meer dan duidelijk. Echter, om de GAN te laten convergen moet men wel de benodigde computer kracht hebben. SRON heeft een cluster, maar helaas zonder grafische kaarten. Gelukkig heb ik goede contacten overgelaten aan mijn minor. Daardoor kon ik de data science server van de Haagse Hogeschool gebruiken. Deze gehele periode was ik (vrijwel) de enige gebruiker van de server. Maar zelfs bij het gebruiken van de volledige capaciteit bleek dat ik dagdelen tot meerdere dagen moest wachten voordat een miniem deel van het resultaat kon zien. Dat brengt het volgende probleem op tafel. 
De vereiste computerkracht is onderschat. Het trainen van een GAN in een redelijk tijdsbestek vereist een van de nieuwste, krachtigste en duurste grafische kaarten van NVIDIA.  Tijdens mijn minor Appied Data Science kwam naar voren dat een lectoraat en de faculteit budget overhadden. Zo kwam ik in contact met Jeroen Vuurens. Een tijdje later hebben we een GPU server samengesteld en geassembleerd. Helaas hadden de grafische kaarten vertraging, hierdoor kon ik pas eind mei gebruik maken van de server. Per toeval kwam ik erachter dat SURFsara computertijd aan SRON beschikbaar kan stellen vanuit het NWO. Hiervoor heb ik een onderzoeksvoorstel ingevuld en ingeleverd. Niet volkomen onverwacht bleek dat Michiel degene was met de bevoegdheid voor een dergelijke aanvraag, en niet ik. Enkele weken en een trip naar Amsterdam verder, en we konden gebruik maken van High Performance Computing (HPC). De representatieve persoon van SURFsara was enthousiast over het onderzoek, helaas bleek dat er slechts een klein aanbod aan oudere grafische kaarten was. De kers op de taart, deze waren constant in gebruik. Uiteindelijk is HPC zeker nodig geweest voor het genereren van de benodigde dataset. Dit, gecombineerd met het geluk dat ik de nieuwe HHs server heb kunnen gebruiken, heeft geleidt tot het resultaat zoals dat nu is.
Ik heb dan wellicht ietwat minder natuurkunde geleerd deze stage. Het is slechts bij algemene begrippen en concepten gebleven. Maar ik heb mij wel volledig kunnen uitleven op het gebied van machine learning. Ondertussen kan ik mijn weg vinden in Linux, het werken met HPC en big-data is als vanouds  en ik heb tot mijn verbazing het e.e.a. aan Fortran geleerd. Al met al was het een zeer leerzame stage. Onderzoek doen gaat niet zoals men voorbarig verwacht. Het is een levendig proces wat alle kanten op kan gaan. In mijn geval is het meer de kant van machine learning op gegaan, in plaats van natuurkunde zoals de bedoeling was. Gelukkig is de potentiele samenhang tussen machine learning en natuurkunde groot, afhankelijk van waar men later terecht komt. 
